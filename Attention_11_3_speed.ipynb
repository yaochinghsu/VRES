{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f9b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence\n",
    "from data_processing import get_data, get_sources_targets_short, get_source_target, get_speed_short, get_with_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e820c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size = 2,\n",
    "                 embedding_size = 128,  # this \"embedding\" is not the real \"embedding\", it is just a y = Ax linear transformation\n",
    "                 hidden_size = 256,\n",
    "                 n_layers = 4,\n",
    "                 bidirectional = False,\n",
    "                 dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout = dropout, bidirectional = bidirectional)\n",
    "               \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # embedded: [sequence len, batch size, embedding size]  #15, 20, 128\n",
    "        embedded = self.dropout(F.relu(self.linear(x)))\n",
    "        encoder_outputs, hidden = self.rnn(embedded, hidden)\n",
    "        return encoder_outputs, hidden  #15, 20, 256 (4, 20, 256)*2\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros((1 + int(self.bidirectional))*self.n_layers, BATCH_SIZE, self.hidden_size),\n",
    "                torch.zeros((1 + int(self.bidirectional))*self.n_layers, BATCH_SIZE, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8715c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_size = 2, \n",
    "                 input_size = 2, \n",
    "                 embedding_size = 128,\n",
    "                 hidden_size = 256,\n",
    "                 n_layers = 4,\n",
    "                 dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Linear(input_size, embedding_size)\n",
    "        self.attn = nn.Linear(hidden_size*2, 1)\n",
    "        self.rnn = nn.LSTM(embedding_size + hidden_size, hidden_size,  n_layers, dropout = dropout)\n",
    "        self.linear_output = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.n_layers, BATCH_SIZE, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, BATCH_SIZE, self.hidden_size))\n",
    "   \n",
    "    def forward(self, input, hidden, all_outputs): #[20, 4], [4,20, 256]*2, [11,15, 20, 256] \n",
    "\n",
    "        input = input.unsqueeze(0)  #[20, 2]=> unsqueeze =[1, 20, 4]\n",
    "        embedded = self.dropout(F.relu(self.embedding(input))) #[1, 20, 4]=> embed =[1, 20, 128]\n",
    "        \n",
    "        attn_applied = (hidden[0][0]*0).unsqueeze(0).expand(all_outputs.size(0),-1, -1)  # 11,20, 256\n",
    "        \n",
    "        \"\"\" find the relationship between the (first decoder) hidden state and each encoder_output, \n",
    "        method: concat hidden[0] and each encoder_output in dim =1, then perform attention \"\"\"\n",
    "        weights = []\n",
    "        for j in range(len(all_outputs)): \n",
    "            for i in range(len(all_outputs[j])):\n",
    "                weights.append(self.attn(torch.cat((hidden[0][0],all_outputs[j][i]), dim = 1))) \n",
    "                # hidden[0] = [4, 20, 256] hidden[0][0] = [20, 256]\n",
    "                # encoder_outputs = [15, 20, 256] encoder_ouputs[i] = [20, 256]\n",
    "                # cat(dim 1) = [20, 512] => att =[20]=> for loop = list of 15*11 each item size 20]\n",
    "\n",
    "        #concat weights in dim = 1,(change list to tensor) and softmax the weight in dim 1\n",
    "        normalized_weights = F.softmax(torch.cat(weights, 1), 1) #20, 15*11\n",
    "        \n",
    "        temp = normalized_weights.view(-1, all_outputs.size(0), all_outputs.size(1)) # 20, 11, 15\n",
    "        \n",
    "        # bmm : batch*n*m X batch*m*p = batch*n*p, therefore, unsqueeze in dim = 1 (n = 1)\n",
    "       \n",
    "        for j in range(len(all_outputs)):\n",
    "            \n",
    "            attn_applied[j] = torch.bmm(temp[:, j, :].unsqueeze(1),all_outputs[j].permute(1, 0, 2)).squeeze(1) \n",
    "            #[20,1,15]X[20,15,256] = [20, 1, 256]\n",
    "        \n",
    "        final_attn_applied = attn_applied.sum(0) #20, 256\n",
    "        \n",
    "        input_lstm = torch.cat((final_attn_applied, embedded[0]), dim = 1)\n",
    "        # embedded = [1, 20, 128]=> layer 0 = [20, 128] concat = [20, 256+128]\n",
    "        \n",
    "        output, hidden = self.rnn(input_lstm.unsqueeze(0), hidden)\n",
    "        \n",
    "        final_output = self.linear_output(output.squeeze(0))\n",
    "        \n",
    "        return final_output, hidden, normalized_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f48d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn_Enc_Dec(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, x, y, target_ordinal, num_target, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "        x = [batch, seq, feature size=11,  4] 20,15, 11, 4\n",
    "        y = [batch, seq, feature size= 1, 4]   20, 15, 5, 4\n",
    "        \n",
    "        \"\"\"\n",
    "        x = x.permute(2, 1, 0, 3) # 11, 15, 20,  4\n",
    "        y = y.permute(2, 1, 0, 3) # 5,15, 20,  4\n",
    "        batch_size = x.shape[2] #20\n",
    "        target_len = y.shape[1] #15\n",
    "        \n",
    "        total_encoder_outputs = (x.repeat(1, 1, 1, int(self.encoder.hidden_size/self.encoder.input_size)).clone())*0 \n",
    "                                                    #11, 15, 20, 256\n",
    "        neighbor_hidden = []\n",
    "        decoder_hidden =self.decoder.init_hidden\n",
    "        for i in range(len(x)): \n",
    "            total_encoder_outputs[i], hidden = self.encoder(x[i], encoder.init_hidden())\n",
    "            neighbor_hidden.append(hidden)\n",
    "            if (i == target_ordinal):\n",
    "                decoder_hidden=hidden\n",
    "       \n",
    "        \n",
    "        outputs = torch.zeros(y.shape).clone().to(self.device) #[5, 15, 20, 4]\n",
    "        \n",
    "        \n",
    "        for j in range(num_target):   \n",
    "            decoder_input = x[target_ordinal+j, -1,:, :]   #[20, 4]\n",
    "\n",
    "            for i in range(target_len):\n",
    "                output, hidden, normalized_weights = self.decoder(decoder_input, decoder_hidden, total_encoder_outputs)     \n",
    "                outputs[j][i] = output #1, 15, 20, 4\n",
    "                teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "                    # output is the same shape as input, [batch_size, feature size]\n",
    "                    # so we can use output directly as input or use true lable depending on\n",
    "                    # teacher_forcing is true or not\n",
    "                decoder_input = y[j][i] if teacher_forcing else output\n",
    "                \n",
    "        outputs = outputs.permute(2, 1, 0, 3)\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040b04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # --------------------------------------------\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        \n",
    "        return self.data[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset\n",
    "        # --------------------------------------------\n",
    "        return len(self.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f3a2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.11965 27.65268] [    0  5621 11154 12562 13750]\n"
     ]
    }
   ],
   "source": [
    "path = './data'\n",
    "#path = 'D:/data'\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(path + \"/*.csv\")))\n",
    "game_data, flag_index = get_data(df)\n",
    "print(game_data[0], flag_index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e5b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ordinal = 0\n",
    "num_source = 11\n",
    "target_ordinal = 1\n",
    "num_target = 3\n",
    "sources, targets = get_sources_targets_short(game_data, flag_index, 15)\n",
    "s_speeds, t_speeds = get_speed_short(game_data, flag_index, 15)\n",
    "# source, target = get_source_target(sources, targets, source_ordinal,num_source,target_ordinal,num_target)\n",
    "source, target =get_with_speed(sources,s_speeds, source_ordinal,num_source,targets, t_speeds, target_ordinal,num_target )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9347707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394 torch.Size([11, 4])\n"
     ]
    }
   ],
   "source": [
    "print(len(source), source[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a0729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "total = []\n",
    "for i in range(len(source)):\n",
    "    temp = (source[i], target[i])\n",
    "    total.append(temp)\n",
    "example = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    temp = (source[i], target[i])\n",
    "    example.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1477af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = MyDataset(total)\n",
    "ex_data =MyDataset(example)\n",
    "train_size = int(len(total_data) * 0.7)\n",
    "val_size = int(len(total_data)*0.2)\n",
    "test_size = len(total_data) - train_size - val_size\n",
    "train_data,val_data, test_data =random_split(total_data, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)\n",
    "ex_loader = DataLoader(ex_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a96213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 15, 11, 4]) torch.Size([20, 15, 3, 4])\n",
      "torch.Size([20, 15, 11, 4]) torch.Size([20, 15, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(iter(train_loader).__next__()[0].shape,iter(train_loader).__next__()[1].shape )\n",
    "print(iter(ex_loader).__next__()[0].shape,iter(ex_loader).__next__()[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6422de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 4\n",
    "OUTPUT_DIM = 4\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 4\n",
    "ENC_DROPOUT = 0\n",
    "DEC_DROPOUT = 0\n",
    "BIDIRECTIONAL = False\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, BIDIRECTIONAL, ENC_DROPOUT)      \n",
    "decoder = AttentionDecoder(OUTPUT_DIM, INPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Attn_Enc_Dec(encoder, decoder, dev).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2005322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        # put data into GPU\n",
    "        x = x.to(dev)\n",
    "        y = y.to(dev)\n",
    "        \n",
    "        # zero all param gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run attetion_encoding to get predictions\n",
    "        y_pred = model(x, y, target_ordinal, num_target, 0.5)\n",
    "        \n",
    "        # get loss and compute model trainable params gradients though backpropagation\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update model params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add batch loss, since loss is single item tensor\n",
    "        # we can get its value by loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = x.to(dev)\n",
    "            y = y.to(dev)\n",
    "            \n",
    "            # turn off teacher forcing\n",
    "            y_pred = model(x, y, target_ordinal, num_target, teacher_forcing_ratio = 0)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "N_EPOCHES = 20\n",
    "best_val_loss = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec03e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully load previous best model parameters\n"
     ]
    }
   ],
   "source": [
    "# load previous best model params if exists\n",
    "model_dir = \"saved_models/attention\"\n",
    "saved_model_path = model_dir + \"/best_attention_11_3_speed.pt\"\n",
    "if os.path.isfile(saved_model_path):\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "    print(\"successfully load previous best model parameters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f03d3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e7be014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time:  1205.3216474056244s\n",
      "\tTrain Loss: 75.597\n",
      "\t Val Loss: 78.040\n",
      "Epoch: 02 | Time:  1154.0935022830963s\n",
      "\tTrain Loss: 69.480\n",
      "\t Val Loss: 76.112\n",
      "Epoch: 03 | Time:  1100.226919412613s\n",
      "\tTrain Loss: 94.934\n",
      "\t Val Loss: 117.411\n",
      "Epoch: 04 | Time:  1099.100618839264s\n",
      "\tTrain Loss: 90.157\n",
      "\t Val Loss: 82.658\n",
      "Epoch: 05 | Time:  1100.6126687526703s\n",
      "\tTrain Loss: 80.523\n",
      "\t Val Loss: 104.411\n",
      "Epoch: 06 | Time:  1097.240463733673s\n",
      "\tTrain Loss: 90.122\n",
      "\t Val Loss: 130.384\n",
      "Epoch: 07 | Time:  1096.4456350803375s\n",
      "\tTrain Loss: 74.285\n",
      "\t Val Loss: 99.015\n",
      "Epoch: 08 | Time:  1096.9986896514893s\n",
      "\tTrain Loss: 78.710\n",
      "\t Val Loss: 101.105\n",
      "Epoch: 09 | Time:  1096.7814173698425s\n",
      "\tTrain Loss: 75.316\n",
      "\t Val Loss: 89.810\n",
      "Epoch: 10 | Time:  1091.5130732059479s\n",
      "\tTrain Loss: 77.263\n",
      "\t Val Loss: 78.244\n",
      "Epoch: 11 | Time:  1093.5724544525146s\n",
      "\tTrain Loss: 68.652\n",
      "\t Val Loss: 97.933\n",
      "Epoch: 12 | Time:  1096.9302244186401s\n",
      "\tTrain Loss: 72.017\n",
      "\t Val Loss: 87.763\n",
      "Epoch: 13 | Time:  1094.8687493801117s\n",
      "\tTrain Loss: 71.796\n",
      "\t Val Loss: 105.074\n",
      "Epoch: 14 | Time:  1090.3961427211761s\n",
      "\tTrain Loss: 83.848\n",
      "\t Val Loss: 87.029\n",
      "Epoch: 15 | Time:  1091.2414197921753s\n",
      "\tTrain Loss: 92.883\n",
      "\t Val Loss: 81.348\n",
      "Epoch: 16 | Time:  1095.1275806427002s\n",
      "\tTrain Loss: 70.944\n",
      "\t Val Loss: 106.946\n",
      "Epoch: 17 | Time:  1093.3351337909698s\n",
      "\tTrain Loss: 63.882\n",
      "\t Val Loss: 63.369\n",
      "Epoch: 18 | Time:  1096.6319615840912s\n",
      "\tTrain Loss: 64.068\n",
      "\t Val Loss: 104.107\n",
      "Epoch: 19 | Time:  1092.6070566177368s\n",
      "\tTrain Loss: 70.700\n",
      "\t Val Loss: 78.319\n",
      "Epoch: 20 | Time:  1088.9486417770386s\n",
      "\tTrain Loss: 65.944\n",
      "\t Val Loss: 65.568\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHES):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    end_time = time.time()\n",
    "    secs = end_time - start_time\n",
    "    \n",
    "    print(F'Epoch: {epoch+1:02} | Time:  {secs}s')\n",
    "    print(F'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(F'\\t Val Loss: {val_loss:.3f}')\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss,epoch)\n",
    "   \n",
    "   \n",
    "   \n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), saved_model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365d2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 62.340\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f}')\n",
    "#  | Test PPL: {math.exp(round(test_loss, 3)):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "186fed22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenes = 2\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(scenes,sharex=True, sharey=True )\n",
    "plt.axis([0, 90, 0, 40])\n",
    "fig.suptitle('Attention Model-- 10 players + 1 ball to predict 3 player')\n",
    "p, q = iter(ex_loader).__next__()  # p [20, 15, 11, 4] q [20, 15, 3, 4]\n",
    "r = model(p, q, target_ordinal, num_target).detach()  #r [20, 15, 3, 4]\n",
    "p_= p.permute(0, 2, 1, 3) #20, 11, 15, 4\n",
    "q_= q.permute(0, 2, 1, 3) \n",
    "r_= r.permute(0, 2, 1, 3)\n",
    "for j in range(scenes):\n",
    "    for i in range(len(p_[j])):\n",
    "        if (i >= target_ordinal and i < target_ordinal + num_target):\n",
    "            axs[j].plot(p_[j][i][:, 0], p_[j][i][:, 1], 'ro', linewidth=0.5, label = \"source\")\n",
    "          \n",
    "        axs[j].plot(p_[j][i][:, 0], p_[j][i][:, 1], color = \"red\", label =\"ref\", )\n",
    "    for i in range(len(q_[j])):\n",
    "        axs[j].plot(q_[j][i][:, 0], q_[j][i][:, 1], \"bx\", linewidth = 0.2, label = \"target\")\n",
    "        axs[j].plot(r_[j][i][:, 0], r_[j][i][:, 1], \"gx\", linewidth = 0.2, label = \"predict\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e773588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = q_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
