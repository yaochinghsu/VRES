{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d459a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence\n",
    "from data_processing import get_data, get_sources_targets_short, get_source_target, get_speed_short, get_with_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48eeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size = 4,\n",
    "                 embedding_size = 128,\n",
    "                 hidden_size = 256,\n",
    "                 n_layers = 4,\n",
    "                 dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers,\n",
    "                           dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        x: input batch data, size: [sequence len, batch size, feature size] #15 20 4\n",
    "        \"\"\"\n",
    "        # embedded: [sequence len, batch size, embedding size]\n",
    "        embedded = self.dropout(F.relu(self.linear(x))) #[100, 20, 128]\n",
    "        # you can checkout https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM\n",
    "        # for details of the return tensor\n",
    "        # briefly speaking, output coontains the output of last layer for each time step\n",
    "        # hidden and cell contains the last time step hidden and cell state of each layer\n",
    "        # we only use hidden and cell as context to feed into decoder\n",
    "        output, hidden = self.rnn(embedded, hidden) # hidden = [4, 20, 256]\n",
    "        # hidden = [n layers * n directions, batch size, hidden size]\n",
    "        # cell = [n layers * n directions, batch size, hidden size]\n",
    "        # the n direction is 1 since we are not using bidirectional RNNs\n",
    "        return hidden\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.n_layers, BATCH_SIZE, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, BATCH_SIZE, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d661b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_size = 4,\n",
    "                 embedding_size = 128,\n",
    "                 hidden_size = 256,\n",
    "                 n_layers = 4,\n",
    "                 dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Linear(output_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout = dropout)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        x : input batch data, size(x): [batch size, feature size]\n",
    "        notice x only has two dimensions since the input is batchs\n",
    "        of last coordinate of observed trajectory\n",
    "        so the sequence length has been removed.\n",
    "        \"\"\"\n",
    "        # add sequence dimension to x, to allow use of nn.LSTM\n",
    "        # after this, size(x) will be [1, batch size, feature size]\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        # embedded = [1, batch size, embedding size]\n",
    "        embedded = self.dropout(F.relu(self.embedding(x)))\n",
    "            \n",
    "        #output = [seq len, batch size, hid dim * n directions]\n",
    "        #hidden = ([n layers * n directions, batch size, hid dim], [n layers * n directions, batch size, hid dim])\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = [1, batch size, hidden size]\n",
    "        #hidden = ([n layers, batch size, hidden size], [n layers, batch size, hidden size])\n",
    "        output, hidden = self.rnn(embedded,hidden)\n",
    "\n",
    "        # prediction = [batch size, output size]\n",
    "        prediction = self.linear(output.squeeze(0))\n",
    "\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a72427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.attn = nn.Linear(self.encoder.hidden_size*2, 1)\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, x, y, target_ordinal =1, num_target = 5,  teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "         x = [batch size, seq len, feature size] 20,15,11,2  \n",
    "         y = [20, 15, 3, 2]\n",
    "        \"\"\"\n",
    "        x = x.permute(2, 1, 0, 3)  #11, 15, 20, 4\n",
    "        y = y.permute(2, 1, 0, 3)  #3, 15, 20, 4\n",
    "        outputs = torch.zeros(y.shape).to(self.device) # 3, 15, 20, 4\n",
    "        \n",
    "        batch_size = x.shape[2]\n",
    "        ref_size = x.shape[0]\n",
    "        target_len = y.shape[1]\n",
    "        \n",
    "        total_h = []\n",
    "        total_c = []\n",
    "        for each_x in x:\n",
    "            \n",
    "            hidden = self.encoder(each_x, self.encoder.init_hidden()) #[4, 20, 256]*2\n",
    "            total_h.append(hidden[0].unsqueeze(0))\n",
    "            total_c.append(hidden[1].unsqueeze(0))\n",
    "        total_hidden= (torch.cat(total_h, dim = 0), torch.cat(total_c, dim = 0))#([11,4, 20,256], [11, 4, 20, 256])\n",
    "        \n",
    "        for j in range(num_target) : #3\n",
    "            \n",
    "            # first input to decoder is last coordinates of x\n",
    "            decoder_input = x[target_ordinal+j, -1, :, :] \n",
    "            hidden_h = total_hidden[0][target_ordinal+j].clone() #[4, 20, 256] \n",
    "            hidden_c = total_hidden[1][target_ordinal+j].clone()\n",
    "            \n",
    "            weights = []\n",
    "            \n",
    "            for neighbor_hidden in total_hidden[0]:  #neighbor_hidden =[4, 20, 256]\n",
    "                weights.append(self.attn(torch.cat((hidden_h[0], neighbor_hidden[0]), dim = 1)))  #each weight = [ 20, 1]\n",
    "            normalized_weights = F.softmax(torch.cat(weights, 1), 1) #[20,11]\n",
    "                \n",
    "               \n",
    "            for i in range(self.decoder.n_layers):\n",
    "                hidden_h[i] = torch.bmm(normalized_weights.unsqueeze(1), total_hidden[0].permute(1, 2, 0, 3)[i]).permute(1, 0, 2)\n",
    "                hidden_c[i] = torch.bmm(normalized_weights.unsqueeze(1), total_hidden[1].permute(1, 2, 0, 3)[i]).permute(1, 0, 2)\n",
    "                   #[20,1, 11]dot[20, 11, 256] = [20, 1, 256] =>[1, 20, 256] =>[4, 20, 256]   \n",
    "            \n",
    "            new_hidden = (hidden_h, hidden_c)\n",
    "            \n",
    "            for i in range(target_len): #15\n",
    "                # run decode for one time step\n",
    "                \n",
    "                output, hidden = self.decoder(decoder_input, new_hidden)\n",
    "\n",
    "                # place predictions in a tensor holding predictions for each time step\n",
    "                \n",
    "                outputs[j][i] = output\n",
    "\n",
    "                # decide if we are going to use teacher forcing or not\n",
    "                teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "\n",
    "                # output is the same shape as input, [batch_size, feature size]\n",
    "                # so we can use output directly as input or use true lable depending on\n",
    "                # teacher_forcing is true or not\n",
    "                decoder_input = y[j][i] if teacher_forcing else output\n",
    "        outputs = outputs.permute(2,1, 0, 3) #5, 15, 20, 4=> 20, 15, 5, 2\n",
    "      \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9974fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # --------------------------------------------\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        \n",
    "        return self.data[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset\n",
    "        # --------------------------------------------\n",
    "        return len(self.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ff6ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.11965 27.65268] [    0  5621 11154 12562 13750]\n"
     ]
    }
   ],
   "source": [
    "path = './data'\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(path + \"/*.csv\")))\n",
    "game_data, flag_index = get_data(df)\n",
    "print(game_data[0], flag_index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31119b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ordinal = 0\n",
    "num_source = 11\n",
    "target_ordinal = 1\n",
    "num_target = 3\n",
    "sources, targets = get_sources_targets_short(game_data, flag_index, 15)\n",
    "s_speeds, t_speeds = get_speed_short(game_data, flag_index, 15)\n",
    "# source, target = get_source_target(sources, targets, source_ordinal,num_source,target_ordinal,num_target)\n",
    "source, target =get_with_speed(sources,s_speeds, source_ordinal,num_source,targets, t_speeds, target_ordinal,num_target )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0148b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "total = []\n",
    "for i in range(len(source)):\n",
    "    temp = (source[i], target[i])\n",
    "    total.append(temp)\n",
    "example = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    temp = (source[i], target[i])\n",
    "    example.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2645fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = MyDataset(total)\n",
    "ex_data =MyDataset(example)\n",
    "train_size = int(len(total_data) * 0.7)\n",
    "val_size = int(len(total_data)*0.2)\n",
    "test_size = len(total_data) - train_size - val_size\n",
    "train_data,val_data, test_data =random_split(total_data, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)\n",
    "ex_loader = DataLoader(ex_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "204c74d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 15, 11, 4]) torch.Size([20, 15, 3, 4])\n",
      "torch.Size([20, 15, 11, 4]) torch.Size([20, 15, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(iter(train_loader).__next__()[0].shape,iter(train_loader).__next__()[1].shape )\n",
    "print(iter(ex_loader).__next__()[0].shape,iter(ex_loader).__next__()[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3271b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 4\n",
    "OUTPUT_DIM = 4\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 4\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Seq2Seq(enc, dec, dev).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1160de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        # put data into GPU\n",
    "        \n",
    "        x = x.to(dev)\n",
    "        y = y.to(dev)\n",
    "        \n",
    "        # zero all param gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run seq2seq to get predictions\n",
    "        y_pred = model(x, y,target_ordinal, num_target, 0.5)\n",
    "#         plt.plot(y_pred[:,0], y_pred[:, 1], color = 'tab:greem')\n",
    "\n",
    "        \n",
    "        # get loss and compute model trainable params gradients though backpropagation\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update model params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add batch loss, since loss is single item tensor\n",
    "        # we can get its value by loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a3aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = x.to(dev)\n",
    "            y = y.to(dev)\n",
    "            \n",
    "            # turn off teacher forcing\n",
    "            y_pred = model(x, y, target_ordinal, num_target, 0)\n",
    "            loss = criterion(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a57a8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHES = 20\n",
    "best_val_loss = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ea384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully load previous best model parameters\n"
     ]
    }
   ],
   "source": [
    "# load previous best model params if exists\n",
    "model_dir = \"saved_models/Seq2Seq\"\n",
    "saved_model_path = model_dir + \"/best_11_3_speed.pt\"\n",
    "if os.path.isfile(saved_model_path):\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "    print(\"successfully load previous best model parameters\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67bd734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "714e3c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time:  135.30418229103088s\n",
      "\tTrain Loss: 73.662\n",
      "\t Val Loss: 78.960\n",
      "Epoch: 02 | Time:  136.1543152332306s\n",
      "\tTrain Loss: 68.162\n",
      "\t Val Loss: 66.336\n",
      "Epoch: 03 | Time:  135.65430569648743s\n",
      "\tTrain Loss: 67.404\n",
      "\t Val Loss: 66.515\n",
      "Epoch: 04 | Time:  137.0430929660797s\n",
      "\tTrain Loss: 66.519\n",
      "\t Val Loss: 70.201\n",
      "Epoch: 05 | Time:  137.04174900054932s\n",
      "\tTrain Loss: 65.270\n",
      "\t Val Loss: 69.413\n",
      "Epoch: 06 | Time:  137.7270474433899s\n",
      "\tTrain Loss: 70.734\n",
      "\t Val Loss: 67.236\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12440/1545000325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12440/2937028844.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# run seq2seq to get predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_ordinal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#         plt.plot(y_pred[:,0], y_pred[:, 1], color = 'tab:greem')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12440/772723363.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y, target_ordinal, num_target, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0meach_x\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[4, 20, 256]*2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mtotal_h\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mtotal_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12440/2785219548.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# hidden and cell contains the last time step hidden and cell state of each layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# we only use hidden and cell as context to feed into decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# hidden = [4, 20, 256]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;31m# hidden = [n layers * n directions, batch size, hidden size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# cell = [n layers * n directions, batch size, hidden size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    693\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHES):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    end_time = time.time()\n",
    "    secs = end_time - start_time\n",
    "    \n",
    "    print(F'Epoch: {epoch+1:02} | Time:  {secs}s')\n",
    "    print(F'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(F'\\t Val Loss: {val_loss:.3f}')\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss,epoch)\n",
    "   \n",
    "   \n",
    "   \n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), saved_model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "484968fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 71.679 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "344e130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenes = 2\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(scenes,sharex=True, sharey=True )\n",
    "plt.axis([0, 90, 0, 40])\n",
    "fig.suptitle('Seq2Seq Model-- 10 players + 1 ball to predict 3 player')\n",
    "p, q = iter(ex_loader).__next__()  # p [20, 15, 11, 4] q [20, 15, 3, 4]\n",
    "r = model(p, q, target_ordinal, num_target).detach()  #r [20, 15, 3, 4]\n",
    "p_= p.permute(0, 2, 1, 3) #20, 11, 15, 4\n",
    "q_= q.permute(0, 2, 1, 3) \n",
    "r_= r.permute(0, 2, 1, 3)\n",
    "for j in range(scenes):\n",
    "    for i in range(len(p_[j])):\n",
    "        if (i >= target_ordinal and i < target_ordinal + num_target):\n",
    "            axs[j].plot(p_[j][i][:, 0], p_[j][i][:, 1], 'ro', linewidth=0.5, label = \"source\")\n",
    "          \n",
    "        axs[j].plot(p_[j][i][:, 0], p_[j][i][:, 1], color = \"red\", label =\"ref\", )\n",
    "    for i in range(len(q_[j])):\n",
    "        axs[j].plot(q_[j][i][:, 0], q_[j][i][:, 1], \"bx\", linewidth = 0.2, label = \"target\")\n",
    "        axs[j].plot(r_[j][i][:, 0], r_[j][i][:, 1], \"gx\", linewidth = 0.2, label = \"predict\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2256c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2a323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
