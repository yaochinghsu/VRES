{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f9b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "from torch import Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence\n",
    "from data_processing import get_data, get_sources_targets_short, get_source_target, get_speed_short, get_with_speed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80422ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "    temp = query.bmm(key.transpose(1, 2))\n",
    "    scale = query.size(-1) ** 0.5\n",
    "    softmax = F.softmax(temp / scale, dim=-1)\n",
    "    return softmax.bmm(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79a4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, dim_in: int, dim_q: int, dim_k: int):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(dim_in, dim_q)\n",
    "        self.k = nn.Linear(dim_in, dim_k)\n",
    "        self.v = nn.Linear(dim_in, dim_k)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        \n",
    "        return scaled_dot_product_attention(self.q(query), self.k(key), self.v(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a556e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, dim_in: int, dim_q: int, dim_k: int):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(dim_in, dim_q, dim_k) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * dim_k, dim_in)\n",
    "\n",
    "    def forward(self, query: Tensor, key: Tensor, value: Tensor) -> Tensor:\n",
    "        \n",
    "        return self.linear(\n",
    "            torch.cat([h(query, key, value) for h in self.heads], dim=-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d8fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(\n",
    "    seq_len: int, dim_model: int, device: torch.device = torch.device(\"cpu\"),\n",
    ") -> Tensor:\n",
    "    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n",
    "    dim = torch.arange(dim_model, dtype=torch.float, device=device).reshape(1, 1, -1)\n",
    "    phase = pos / (1e4 ** (dim // dim_model))\n",
    "\n",
    "    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b3385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(dim_input: int = 512, dim_feedforward: int = 2048) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim_input, dim_feedforward),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(dim_feedforward, dim_input),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4919954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm = nn.LayerNorm(dimension)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, *tensors: Tensor) -> Tensor:\n",
    "        # Assume that the \"query\" tensor is given first, so we can compute the\n",
    "        # residual.  This matches the signature of 'MultiHeadAttention'.\n",
    "        return self.norm(tensors[0] + self.dropout(self.sublayer(*tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbb7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 3,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_q = dim_k = max(dim_model // num_heads, 1)\n",
    "        self.attention = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.feed_forward = Residual(\n",
    "            feed_forward(dim_model, dim_feedforward),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        src = self.attention(src, src, src)\n",
    "        return self.feed_forward(src)\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 4,\n",
    "        num_layers: int = 3,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 3,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.linear_in = nn.Linear(input_size, dim_model)\n",
    "        \n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        embedded = self.linear_in(src)\n",
    "        seq_len, dimension = embedded.size(1), embedded.size(2)\n",
    "        \n",
    "        embedded += position_encoding(seq_len, dimension)\n",
    "        for layer in self.layers:\n",
    "            embedded = layer(embedded)\n",
    "        \n",
    "        return embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b68eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 3,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_q = dim_k = max(dim_model // num_heads, 1)\n",
    "       \n",
    "        self.attention = Residual(\n",
    "            MultiHeadAttention(num_heads, dim_model, dim_q, dim_k),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.feed_forward = Residual(\n",
    "            feed_forward(dim_model, dim_feedforward),\n",
    "            dimension=dim_model,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor) -> Tensor:\n",
    "       \n",
    "        \n",
    "        tgt = self.attention(tgt, memory, memory)\n",
    "        return self.feed_forward(tgt)\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_size: int = 4,\n",
    "        num_layers: int = 3,\n",
    "        dim_model: int = 512,\n",
    "        num_heads: int = 8,\n",
    "        dim_feedforward: int = 2048,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerDecoderLayer(dim_model, num_heads, dim_feedforward, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "       \n",
    "        self.linear_out = nn.Linear(dim_model, output_size)\n",
    "        \n",
    "    def forward(self, tgt: Tensor, memory: Tensor) -> Tensor:\n",
    "        for layer in self.layers:\n",
    "            tgt = layer(tgt, memory) #[20, 500, 512], [20. 1100.512]=> [20, 500, 512]\n",
    "        \n",
    "        outputs = self.linear_out(tgt).view(num_target, tgt.shape[0], -1, self.output_size)\n",
    "        \n",
    "        \n",
    "        return outputs.permute(1, 2, 0, 3)  #11, 20, 100, 2=>20,100,11,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9739d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_encoder_layers: int = 6,\n",
    "        num_decoder_layers: int = 6,\n",
    "        dim_model: int = 512, \n",
    "        num_heads: int = 3, \n",
    "        dim_feedforward: int = 2048, \n",
    "        dropout: float = 0.1, \n",
    "        activation: nn.Module = nn.ReLU(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(\n",
    "            num_layers=num_encoder_layers,\n",
    "            dim_model=dim_model,\n",
    "            num_heads=num_heads,\n",
    "            \n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(\n",
    "            num_layers=num_decoder_layers,\n",
    "            dim_model=dim_model,\n",
    "            num_heads=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "       \n",
    "        src_permute = src.permute(2, 0, 1, 3) #20, 100  11, 2=> 11, 20, 100, 2\n",
    "        temp = []\n",
    "        tgt_src = []\n",
    "        \n",
    "        for i, each_src in enumerate(src_permute):\n",
    "            enc = self.encoder(each_src)\n",
    "            temp.append(enc)  # 11 of #encoder[20, 100, 2]=>[20, 100, 512]\n",
    "            if (i < num_target):\n",
    "                tgt_src.append(enc)\n",
    "                \n",
    "        total_enc = torch.cat(temp, dim = 1)  #20, 100*11, 512\n",
    "        tgt = torch.cat(tgt_src, dim = 1)  #20, 100*5, 512\n",
    "        return self.decoder(tgt, total_enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040b04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        # --------------------------------------------\n",
    "        # Initialize paths, transforms, and so on\n",
    "        # --------------------------------------------\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # --------------------------------------------\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        # --------------------------------------------\n",
    "        \n",
    "        return self.data[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        # --------------------------------------------\n",
    "        # Indicate the total size of the dataset\n",
    "        # --------------------------------------------\n",
    "        return len(self.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3a2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.11965 27.65268] [    0  5621 11154 12562 13750]\n"
     ]
    }
   ],
   "source": [
    "path = './data'\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(path + \"/*.csv\")))\n",
    "# path = 'D:/VRE_project/nba-movement-data/data/csv/0021500001.csv'\n",
    "# df = pd.read_csv(path)\n",
    "game_data, flag_index = get_data(df)\n",
    "print(game_data[0], flag_index[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e5b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ordinal = 0\n",
    "num_source = 11\n",
    "target_ordinal = 1\n",
    "num_target = 3\n",
    "sources, targets = get_sources_targets_short(game_data, flag_index, 15)\n",
    "s_speeds, t_speeds = get_speed_short(game_data, flag_index, 15)\n",
    "# source, target = get_source_target(sources, targets, source_ordinal,num_source,target_ordinal,num_target)\n",
    "source, target =get_with_speed(sources,s_speeds, source_ordinal,num_source,targets, t_speeds, target_ordinal,num_target )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59eaa9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394 torch.Size([11, 4])\n"
     ]
    }
   ],
   "source": [
    "print(len(source), source[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a0729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "total = []\n",
    "for i in range(len(source)):\n",
    "    temp = (source[i], target[i])\n",
    "    total.append(temp)\n",
    "example = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    temp = (source[i], target[i])\n",
    "    example.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f079115",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = MyDataset(total)\n",
    "ex_data =MyDataset(example)\n",
    "train_size = int(len(total_data) * 0.7)\n",
    "val_size = int(len(total_data)*0.2)\n",
    "test_size = len(total_data) - train_size - val_size\n",
    "train_data,val_data, test_data =random_split(total_data, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = True)\n",
    "ex_loader = DataLoader(ex_data, batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9058d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 15, 11, 4]) torch.Size([20, 15, 3, 4])\n",
      "torch.Size([20, 15, 11, 4]) torch.Size([20, 15, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(iter(train_loader).__next__()[0].shape,iter(train_loader).__next__()[1].shape )\n",
    "print(iter(ex_loader).__next__()[0].shape,iter(ex_loader).__next__()[1].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36ef54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer().to(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2005322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        # put data into GPU\n",
    "        x = x.to(dev)\n",
    "        y = y.to(dev)\n",
    "        \n",
    "        # zero all param gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run attetion_encoding to get predictions\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # get loss and compute model trainable params gradients though backpropagation\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update model params\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add batch loss, since loss is single item tensor\n",
    "        # we can get its value by loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = x.to(dev)\n",
    "            y = y.to(dev)\n",
    "            \n",
    "            # turn off teacher forcing\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ef84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHES = 20\n",
    "best_val_loss = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d81a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f917e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ebea6724ae9b>:6: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  phase = pos / (1e4 ** (dim // dim_model))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time:  529.0858864784241s\n",
      "\tTrain Loss: 250.520\n",
      "\t Val. Loss: 217.321\n",
      "Epoch: 02 | Time:  531.924756526947s\n",
      "\tTrain Loss: 219.035\n",
      "\t Val. Loss: 257.165\n",
      "Epoch: 03 | Time:  525.7669937610626s\n",
      "\tTrain Loss: 220.906\n",
      "\t Val. Loss: 216.130\n"
     ]
    }
   ],
   "source": [
    "# load previous best model params if exists\n",
    "model_dir = \"saved_models/tranformer\"\n",
    "saved_model_path = model_dir + \"/best_transformer_11_3_speed.pt\"\n",
    "# if os.path.isfile(saved_model_path):\n",
    "#     model.load_state_dict(torch.load(saved_model_path))\n",
    "#     print(\"successfully load previous best model parameters\")\n",
    "    \n",
    "for epoch in range(N_EPOCHES):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "   \n",
    "    end_time = time.time()\n",
    "    \n",
    "    secs = end_time - start_time\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss,epoch)\n",
    "   \n",
    "    print(F'Epoch: {epoch+1:02} | Time:  {secs}s')\n",
    "    print(F'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(F'\\t Val. Loss: {val_loss:.3f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        torch.save(model.state_dict(), saved_model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "365d2657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ebea6724ae9b>:6: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  phase = pos / (1e4 ** (dim // dim_model))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 214.952 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} ')\n",
    "# | Test PPL: {math.exp(round(test_loss, 3)):7.3f} |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86bc2ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ebea6724ae9b>:6: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  phase = pos / (1e4 ** (dim // dim_model))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenes = 2\n",
    "plt.clf()\n",
    "fig, axs = plt.subplots(scenes,sharex=True, sharey=True )\n",
    "plt.axis([0, 90, 0, 40])\n",
    "fig.suptitle('Transformer Model--  10 players + 1 ball to predict 3 player')\n",
    "p, q = iter(ex_loader).__next__()  # p [20, 15, 11, 4] q [20, 15, 3, 4]\n",
    "r = model(p).detach()  #r [20, 15, 3, 4]\n",
    "p_= p.permute(0, 2, 1, 3) #20, 11, 15, 4\n",
    "q_= q.permute(0, 2, 1, 3) \n",
    "r_= r.permute(0, 2, 1, 3)\n",
    "for j in range(scenes):\n",
    "    for i in range(len(p_[j])):\n",
    "        if (i >= target_ordinal and i < target_ordinal + num_target):\n",
    "            axs[j].plot(p_[j][i][:, 0], p_[j][i][:, 1], 'ro', linewidth=0.5, label = \"source\")\n",
    "          \n",
    "        axs[j].plot(p_[j][i][:, 0], p_[j][i][:, 1], color = \"red\", label =\"ref\", )\n",
    "    for i in range(len(q_[j])):\n",
    "        axs[j].plot(q_[j][i][:, 0], q_[j][i][:, 1], \"bx\", linewidth = 0.2, label = \"target\")\n",
    "        axs[j].plot(r_[j][i][:, 0], r_[j][i][:, 1], \"gx\", linewidth = 0.2, label = \"predict\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83688e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab148743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
